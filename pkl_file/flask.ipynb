{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec491b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaler.pkl created.\n",
      "churn_model.pkl created.\n"
     ]
    }
   ],
   "source": [
    "# create_dummy_models.py\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Dummy Model 1\n",
    "model1 = LogisticRegression()\n",
    "# Create some dummy data to fit the model\n",
    "X_dummy = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y_dummy = np.array([0, 1, 0, 1])\n",
    "model1.fit(X_dummy, y_dummy)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(model1, f)\n",
    "\n",
    "print(\"scaler.pkl created.\")\n",
    "\n",
    "# Dummy Model 2 (e.g., a different model or trained on different data)\n",
    "model2 = LogisticRegression()\n",
    "X_dummy_2 = np.array([[10, 11], [12, 13], [14, 15], [16, 17]])\n",
    "y_dummy_2 = np.array([1, 0, 1, 0])\n",
    "model2.fit(X_dummy_2, y_dummy_2)\n",
    "\n",
    "with open('churn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model2, f)\n",
    "\n",
    "print(\"churn_model.pkl created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eac7d29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaler.pkl loaded successfully.\n",
      "churn_model.pkl loaded successfully.\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys # For error logging\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# --- Global variables for loaded models ---\n",
    "# Initialize to None, they will be loaded on startup\n",
    "scaler_model = None\n",
    "churn_prediction_model = None\n",
    "\n",
    "# --- Function to load models ---\n",
    "def load_models():\n",
    "    global scaler_model, churn_prediction_model\n",
    "    try:\n",
    "        # Load the StandardScaler\n",
    "        with open('scaler.pkl', 'rb') as f:\n",
    "            scaler_model = pickle.load(f)\n",
    "        print(\"scaler.pkl loaded successfully.\")\n",
    "\n",
    "        # Load the Churn Prediction Model\n",
    "        with open('churn_model.pkl', 'rb') as f:\n",
    "            churn_prediction_model = pickle.load(f)\n",
    "        print(\"churn_model.pkl loaded successfully.\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"CRITICAL ERROR: A required model file was not found: {e}. Please ensure 'scaler.pkl' and 'churn_model.pkl' are in the same directory as 'app.py'.\", file=sys.stderr)\n",
    "        sys.exit(1) # Exit if critical models are not found\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR: An unexpected error occurred while loading models: {e}\", file=sys.stderr)\n",
    "        sys.exit(1) # Exit on any other critical loading error\n",
    "\n",
    "# Load models when the application starts\n",
    "# This block runs once when app.py is executed\n",
    "with app.app_context():\n",
    "    load_models()\n",
    "\n",
    "# --- API Endpoints ---\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    \"\"\"\n",
    "    Renders the main interface page for churn prediction.\n",
    "    Assumes 'index.html' exists in a 'templates' subfolder.\n",
    "    \"\"\"\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict_churn', methods=['POST'])\n",
    "def predict_churn():\n",
    "    \"\"\"\n",
    "    API endpoint to predict churn using the loaded scaler and churn model.\n",
    "    Expects JSON input with 'features' key containing a list of numbers.\n",
    "    The number of features must match what the model was trained on.\n",
    "    \"\"\"\n",
    "    # Check if models were loaded successfully at startup\n",
    "    if scaler_model is None or churn_prediction_model is None:\n",
    "        return jsonify({'error': 'Models are not loaded. Server startup failed or models are missing.'}), 500\n",
    "\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        if not data or 'features' not in data:\n",
    "            return jsonify({'error': 'Invalid input: JSON with \"features\" key (list of numbers) expected.'}), 400\n",
    "\n",
    "        input_features = np.array(data['features'])\n",
    "\n",
    "        # --- IMPORTANT: Adjust 'expected_features_count' to your actual model's input size ---\n",
    "        # For example, if your model was trained on 10 features, set this to 10.\n",
    "        expected_features_count = 5 # <--- CHANGE THIS TO THE ACTUAL NUMBER OF FEATURES YOUR MODEL EXPECTS\n",
    "        if input_features.shape[0] != expected_features_count:\n",
    "            return jsonify({\n",
    "                'error': f'Invalid number of features. Expected {expected_features_count} but received {input_features.shape[0]}.',\n",
    "                'received_features': input_features.tolist()\n",
    "            }), 400\n",
    "\n",
    "        # Reshape for single prediction (1 sample, N features)\n",
    "        reshaped_features = input_features.reshape(1, -1)\n",
    "\n",
    "        # Step 1: Scale the features using the loaded scaler\n",
    "        scaled_features = scaler_model.transform(reshaped_features)\n",
    "\n",
    "        # Step 2: Make prediction with the churn model\n",
    "        prediction = churn_prediction_model.predict(scaled_features).tolist()\n",
    "        probability = churn_prediction_model.predict_proba(scaled_features).tolist() if hasattr(churn_prediction_model, 'predict_proba') else None\n",
    "\n",
    "        # Return results\n",
    "        return jsonify({\n",
    "            'input_features': input_features.tolist(),\n",
    "            'scaled_features_for_model': scaled_features.tolist(), # Can be useful for debugging\n",
    "            'churn_prediction': prediction[0], # Assuming single prediction, take first element\n",
    "            'churn_probability': probability[0] if probability else None # Assuming binary classification, first sample\n",
    "        })\n",
    "\n",
    "    except ValueError as ve:\n",
    "        # Catch errors if input_features cannot be converted to numpy array or reshaped\n",
    "        print(f\"ValueError during prediction: {ve}\", file=sys.stderr)\n",
    "        return jsonify({'error': f'Data conversion error: {str(ve)}. Ensure all features are numeric.'}), 400\n",
    "    except Exception as e:\n",
    "        # Catch any other unexpected errors during prediction\n",
    "        print(f\"An unexpected error occurred during prediction: {e}\", file=sys.stderr)\n",
    "        return jsonify({'error': f'An internal server error occurred during prediction: {str(e)}. Check server logs for details.'}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Run the Flask development server\n",
    "    # debug=True allows automatic reloading on code changes and provides a debugger\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdbeeea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a2650e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
